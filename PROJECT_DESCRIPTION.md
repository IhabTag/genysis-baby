# GENYSIS-BABY: AGI Infant Development System

## ğŸ¯ Project Overview

**GENYSIS-BABY** is an ambitious artificial general intelligence (AGI) research project that simulates the cognitive development of a newborn AI agent. The project implements a curiosity-driven learning system that perceives, learns, and interacts with a computer desktop environment through a biologically-inspired developmental approach.

This is the core developmental module of the broader Genysis AGI project, focusing on foundational learning mechanisms that mirror early human cognitive development.

## ğŸ§  Core Concept

The project simulates an "AGI infant" that:
- **Perceives** its world through visual observation (desktop screen capture)
- **Acts** through motor control (mouse and keyboard interactions)
- **Learns** through self-supervised world modeling and curiosity-driven exploration
- **Remembers** through episodic and semantic memory systems
- **Grows** through continuous online learning and self-improvement

## ğŸ—ï¸ System Architecture

### 1. **Environment Layer** (`env/`)
The sensorimotor interface between the agent and the computer desktop environment.

- **`computer_env.py`**: Gym-like environment wrapper providing:
  - Observation space: RGB screen captures (HÃ—WÃ—3)
  - Action space: Mouse movements, clicks, keyboard input, scrolling
  - Episode management and logging
  - Configurable screen resolution (default: 1280Ã—1024)

- **`obs.py`**: Screen capture using MSS (Multiple Screen Shots)
  - Real-time desktop frame acquisition
  - Configurable resolution and region

- **`actions.py`**: Action execution via PyAutoGUI
  - Mouse movements (absolute and relative)
  - Left/right clicks
  - Keyboard typing
  - Scroll actions

- **`logging.py`**: Episode logging and data persistence
  - Saves observations, actions, and metadata
  - Structured episode directories

### 2. **World Model** (`models/`)
Neural network-based predictive model of the environment dynamics.

**Core Architecture** (`world_model.py`):
- **Encoder**: Convolutional neural network that compresses visual observations into latent representations (z)
- **Projection Head**: Maps latent states to contrastive learning space (p) for similarity comparisons
- **Dynamics Model**: Predicts next latent state given current state and action: `f(z_t, a_t) â†’ z_{t+1}`
- **Decoder**: Reconstructs predicted next frame from predicted latent state

**Model Utilities** (`models/utils/`):
- **`encoder_blocks.py`**: Convolutional encoder/decoder architectures
- **`preprocessing.py`**: Frame normalization, action encoding, and data preparation
- **`attention.py`**: Visual attention mechanism for saliency detection
- **`ocr.py`**: Optical character recognition for text extraction (Tesseract-based)
- **`patch_embeddings.py`**: Patch-based visual feature extraction
- **`projection_head.py`**: Contrastive learning projection layers
- **`dynamics.py`**: State transition prediction networks

**Learning Objectives**:
1. **Reconstruction Loss**: Minimize pixel-level prediction error
2. **Latent Consistency**: Ensure predicted latent states match true encoded states
3. **Contrastive Learning**: Learn meaningful representations through similarity comparisons

### 3. **Memory Systems** (`memory/`)

**`episodic_buffer.py`**: Short-term episodic memory
- Stores recent state projections (p_t) in contrastive space
- Fixed-size circular buffer (default: 1500 entries)
- Used for novelty detection and state comparison

**`text_memory.py`**: Semantic text memory
- Tracks observed text elements from OCR
- Maintains frequency counts and recency information
- Enables text-based novelty detection

**`replay_buffer.py`**: Experience replay storage
- Stores (state, action, next_state) transitions
- Supports offline training and batch learning

**`curiosity.py`**: Intrinsic motivation module
Computes multi-factor curiosity scores:
1. **Latent Curiosity**: `||p_pred - p_true||Â²` (prediction error in contrastive space)
2. **Novelty Curiosity**: Distance to nearest memory embedding
3. **Attention Curiosity**: `||A_pred - A_true||Â²` (attention map changes)

Combined formula:
```
curiosity = w_latent Ã— latent_error + w_novelty Ã— novelty + w_attention Ã— attention_error
```

### 4. **Agent Systems** (`agent/`)

**`curious_agent.py`**: Main curiosity-driven agent (559 lines)
- **Action Selection**: Generates and evaluates candidate actions based on curiosity
- **Multi-Factor Curiosity**: Combines latent change, text novelty, layout change, and goal alignment
- **Fast Mode**: Optimized inference path that skips OCR on predicted frames
- **Persistent Memory**: Maintains episodic, text, and goal memories across sessions
- **State Persistence**: Saves/loads complete agent state for lifelong learning

**Key Features**:
- Candidate action generation (mouse moves, clicks, scrolls, text-targeted actions)
- Screen interpretation via OCR
- Text signature and layout signature for state comparison
- Boredom mechanism to avoid repetitive actions
- Goal-based curiosity for task-oriented exploration

**`random_agent.py`**: Baseline random exploration agent
- Generates random actions for comparison and fallback
- Used for initial data collection

**`instruction_agent.py`**: Natural language instruction executor
- Parses simple text commands
- Maps commands to action sequences

**`text_actions.py`**: Text-aware action agent
- Targets interactive elements detected via OCR
- Clicks on buttons, links, and text elements

**`task_planner.py`**: Multi-step task planning and verification
- Decomposes complex instructions into substeps
- Executes with verification (OCR change, screen change, pixel difference)
- Retry logic for failed steps

**`screen_interpreter.py`**: Screen understanding module
- OCR-based element detection
- Screen layout analysis

**`goal_head.py`**: Goal-oriented curiosity head
- Learns goal representations
- Computes goal alignment scores

**`command_parser.py`**: Natural language command parsing
- Extracts action parameters from text instructions

### 5. **Training Scripts** (`scripts/`)

**Data Collection**:
- **`collect_random_dataset.py`**: Generate offline exploration dataset with random actions
  - Creates structured episode directories
  - Saves observations and actions for supervised training

**World Model Training**:
- **`train_world_model_contrastive.py`**: Offline contrastive learning
  - Trains on collected datasets
  - Combines reconstruction and contrastive losses
  - Saves checkpoints to `checkpoints/world_model_contrastive.pt`

**Inference & Testing**:
- **`run_world_model_inference.py`**: Test forward pass and predictions
- **`test_curious_agent.py`**: Validate curiosity-driven behavior
- **`run_curious_training.py`**: Online curiosity-driven exploration loop

**Lifelong Learning**:
- **`online_lifelong_learning.py`**: Continuous learning system
  - Persistent agent state across sessions
  - Tracks "cognitive age" (total episodes and steps)
  - Online world model updates during exploration
  - Saves state, memory, and age metrics
  - Runs indefinitely for developmental progression

**Debug Tools** (`scripts/debug/`):
- `test_obs.py`: Verify screen capture
- `test_actions.py`: Test mouse/keyboard control
- `test_attn.py`: Validate attention maps
- `print_shapes.py`: Check data tensor shapes

## ğŸ”¬ Key Innovations

### 1. **Curiosity-Driven Learning**
Unlike traditional RL agents that require external rewards, GENYSIS-BABY is intrinsically motivated by:
- Prediction errors (what surprises the model)
- Novelty (what hasn't been seen before)
- Attention changes (what's visually salient)
- Goal alignment (what matches learned objectives)

### 2. **Developmental Approach**
The system tracks "cognitive age" based on total experience:
- ~50,000 steps â‰ˆ 1 human cognitive month (heuristic)
- Persistent memory across sessions
- Continuous learning without catastrophic forgetting

### 3. **Multi-Modal Perception**
Combines:
- Raw pixel observations
- Learned latent representations
- OCR text extraction
- Visual attention maps
- Layout signatures

### 4. **Fast Mode Optimization**
Intelligent inference path that:
- Skips expensive OCR on predicted frames
- Samples episodic memory for efficiency
- Reduces candidate actions for speed
- Maintains exploration quality

### 5. **Hierarchical Action Selection**
- Low-level: Random motor babbling
- Mid-level: Curiosity-driven exploration
- High-level: Instruction following and task planning

## ğŸ› ï¸ Technology Stack

**Core ML/AI**:
- PyTorch 2.1.0 (neural networks and training)
- TorchVision 0.16.0 (vision utilities)

**Computer Vision**:
- OpenCV 4.8.1 (image processing)
- Pillow 10.0.1 (image I/O)
- Matplotlib 3.8.0 (visualization)

**Environment Control**:
- MSS 9.0.1 (screen capture)
- PyAutoGUI 0.9.54 (mouse/keyboard control)
- pynput 1.7.6 (input monitoring)
- python-xlib 0.33 (X11 interface for Linux)

**OCR**:
- Tesseract OCR (external dependency)
- pytesseract (Python wrapper)

**Utilities**:
- NumPy 1.25.2 (numerical computing)
- SciPy 1.11.3 (scientific computing)
- tqdm 4.66.1 (progress bars)
- psutil 5.9.5 (system monitoring)
- PyYAML 6.0.1 (configuration)

**Infrastructure**:
- Docker (containerized environment)
- VNC (remote desktop access)
- Xvfb (virtual framebuffer)
- Openbox (lightweight window manager)

## ğŸ³ Deployment Architecture

The system runs in a sandboxed Docker container (`genysis-sandbox` - separate repository):
- Full Linux desktop environment
- VNC server on port 5900
- Isolated from host system
- Pre-configured GUI libraries and dependencies

**Workflow**:
1. Build and run `genysis-sandbox` Docker container
2. Connect via VNC to view the "baby's world"
3. Inside container: clone `genysis-baby` repository
4. Install Python dependencies in virtualenv
5. Run training/exploration scripts
6. Observe autonomous learning behavior

## ğŸ“Š Data Flow

```
Screen Capture â†’ Preprocessing â†’ Encoder â†’ Latent State (z)
                                              â†“
                                         Projection (p)
                                              â†“
                                    Episodic Memory Storage
                                              â†“
Action Candidates â† Curiosity Scoring â† Memory Comparison
        â†“
Action Execution â†’ Environment Change â†’ Next Observation
        â†“
World Model Training (online or offline)
```

## ğŸ“ Learning Pipeline

### Phase 1: Bootstrap (Offline)
1. Collect random exploration dataset
2. Train world model on collected data
3. Learn basic visual representations

### Phase 2: Curious Exploration (Online)
1. Agent generates candidate actions
2. World model predicts outcomes
3. Curiosity module scores each candidate
4. Execute most curious action
5. Update memory with new experience
6. Incrementally train world model

### Phase 3: Instruction Following
1. Parse natural language commands
2. Decompose into substeps
3. Execute with verification
4. Retry failed steps

### Phase 4: Lifelong Learning
1. Persistent state across sessions
2. Continuous memory accumulation
3. Progressive skill development
4. Age tracking and developmental milestones

## ğŸ“ Project Structure

```
genysis-baby/
â”œâ”€â”€ env/                    # Environment interface
â”‚   â”œâ”€â”€ obs.py             # Screen capture
â”‚   â”œâ”€â”€ actions.py         # Action execution
â”‚   â”œâ”€â”€ logging.py         # Episode logging
â”‚   â””â”€â”€ computer_env.py    # Main environment
â”‚
â”œâ”€â”€ models/                 # Neural network models
â”‚   â”œâ”€â”€ world_model.py     # Unified world model
â”‚   â””â”€â”€ utils/             # Model components
â”‚       â”œâ”€â”€ encoder_blocks.py
â”‚       â”œâ”€â”€ preprocessing.py
â”‚       â”œâ”€â”€ attention.py
â”‚       â”œâ”€â”€ ocr.py
â”‚       â”œâ”€â”€ dynamics.py
â”‚       â”œâ”€â”€ projection_head.py
â”‚       â””â”€â”€ patch_embeddings.py
â”‚
â”œâ”€â”€ memory/                 # Memory systems
â”‚   â”œâ”€â”€ curiosity.py       # Intrinsic motivation
â”‚   â”œâ”€â”€ episodic_buffer.py # Short-term memory
â”‚   â”œâ”€â”€ text_memory.py     # Semantic text memory
â”‚   â””â”€â”€ replay_buffer.py   # Experience replay
â”‚
â”œâ”€â”€ agent/                  # Agent implementations
â”‚   â”œâ”€â”€ curious_agent.py   # Main curiosity agent
â”‚   â”œâ”€â”€ random_agent.py    # Baseline agent
â”‚   â”œâ”€â”€ instruction_agent.py
â”‚   â”œâ”€â”€ text_actions.py
â”‚   â”œâ”€â”€ task_planner.py
â”‚   â”œâ”€â”€ screen_interpreter.py
â”‚   â”œâ”€â”€ goal_head.py
â”‚   â””â”€â”€ command_parser.py
â”‚
â”œâ”€â”€ scripts/                # Training & testing
â”‚   â”œâ”€â”€ collect_random_dataset.py
â”‚   â”œâ”€â”€ train_world_model_contrastive.py
â”‚   â”œâ”€â”€ run_world_model_inference.py
â”‚   â”œâ”€â”€ test_curious_agent.py
â”‚   â”œâ”€â”€ run_curious_training.py
â”‚   â”œâ”€â”€ online_lifelong_learning.py
â”‚   â””â”€â”€ debug/             # Debug utilities
â”‚
â”œâ”€â”€ datasets/               # Collected data
â”œâ”€â”€ checkpoints/            # Model weights
â”œâ”€â”€ state/                  # Agent persistent state
â”œâ”€â”€ logs/                   # Episode logs
â”œâ”€â”€ text/                   # Text data
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.MD              # Setup instructions
```

## ğŸ¯ Research Goals

1. **Developmental AI**: Study how artificial agents can learn through curiosity-driven exploration, similar to infant development
2. **Self-Supervised Learning**: Minimize reliance on external rewards and labels
3. **Continual Learning**: Enable lifelong learning without catastrophic forgetting
4. **Emergent Behavior**: Observe complex behaviors emerging from simple curiosity mechanisms
5. **World Modeling**: Learn predictive models of environment dynamics
6. **Transfer Learning**: Develop skills that transfer across tasks

## ğŸš€ Future Directions

- **Language Models**: Integrate LLMs for better instruction understanding
- **Multi-Modal Fusion**: Combine vision, audio, and text modalities
- **Hierarchical Planning**: More sophisticated task decomposition
- **Social Learning**: Learn from demonstrations and human feedback
- **Meta-Learning**: Learn how to learn more efficiently
- **Sim-to-Real**: Transfer learned behaviors to real-world robotics

## ğŸ” Verification & Testing

The project includes comprehensive smoke tests:
1. âœ… Screen capture functionality
2. âœ… Mouse/keyboard action execution
3. âœ… Environment reset/step cycle
4. âœ… Dataset collection pipeline
5. âœ… World model forward pass
6. âœ… World model training loop
7. âœ… Attention map generation
8. âœ… Curious agent behavior
9. âœ… Online training loop
10. âœ… Lifelong learning persistence

## ğŸ“ Key Metrics

- **Cognitive Age**: Total steps / 50,000 â‰ˆ months of development
- **Curiosity Score**: Multi-factor intrinsic motivation value
- **Prediction Error**: World model accuracy (MSE)
- **Memory Size**: Number of unique states remembered
- **Text Novelty**: Unique text elements discovered
- **Episode Length**: Steps before termination
- **Exploration Coverage**: Unique screen states visited

## ğŸ“ Scientific Foundations

The project draws inspiration from:
- **Developmental Psychology**: Infant learning and exploration
- **Neuroscience**: Predictive coding and curiosity in the brain
- **Reinforcement Learning**: Intrinsic motivation and exploration bonuses
- **Self-Supervised Learning**: Contrastive learning and world models
- **Cognitive Science**: Episodic memory and attention mechanisms

## ğŸ† Project Status

**Current Capabilities**:
- âœ… Autonomous desktop exploration
- âœ… Curiosity-driven action selection
- âœ… Online world model learning
- âœ… Persistent memory across sessions
- âœ… OCR-based screen understanding
- âœ… Basic instruction following
- âœ… Lifelong learning with age tracking

**In Development**:
- ğŸ”„ Advanced task planning
- ğŸ”„ Goal-oriented behavior
- ğŸ”„ Language model integration
- ğŸ”„ Hierarchical skill learning

## ğŸ‘¥ Target Audience

- **AI Researchers**: Studying developmental AI and curiosity-driven learning
- **ML Engineers**: Implementing self-supervised learning systems
- **Cognitive Scientists**: Modeling infant cognitive development
- **Roboticists**: Developing autonomous exploration systems
- **Students**: Learning about AGI, world models, and intrinsic motivation

## ğŸ“„ License & Attribution

This is a research project exploring artificial general intelligence through developmental approaches. The codebase demonstrates a complete implementation of curiosity-driven learning in a computer environment.

---

**GENYSIS-BABY** represents a step toward artificial general intelligence through biologically-inspired developmental learning. By simulating the curiosity and exploration of a newborn, the system aims to discover fundamental learning mechanisms that could scale to more complex cognitive abilities.
